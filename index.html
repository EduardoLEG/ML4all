---
layout: default
---
<div class="home">

<div class="site-header-container {% if site.cover %}has-cover{% endif %}" {% if site.cover %}style="background-image: url({{ site.cover | prepend: site.baseurl }});"{% endif %}>
  <div class="scrim {% if site.cover %}has-cover{% endif %}">
    <header class="site-header">
      <h1 class="title">{{ site.title }}</h1>
      {% if site.subtitle %}<p class="subtitle">{{ site.subtitle }}</p>{% endif %}
    </header>
  </div>
</div>

<div class="wrapper">	
<hr>

<h1 id="list_types">Programa da disciplina</h1>
	
<h3>Introdução</h3>
  <ul>
  <li>Machine Learning na prática;</li>
  <li>Aprendizado supervisionado e não supervisionado;</li>
  <li>Função custo;</li>
  </ul>

<h3>Métodos de reamostragem</h3>
  <ul>
  <li>Estimando o erro de previsão;</li>
  <li>Validação cruzada;</li>
  <li>Bootstrap.</li>
  </ul>
	
<h3>Gradiente descendente</h3>
  <ul>
  <li>Batch;</li>
  <li>Stochastic;</li>
  <li>Boosting.</li>
  </ul>
	
<h3>Regularização</h3>
  <ul>
  <li>Regressão Ridge;</li>
  <li>Regressão Lasso;</li>
  <li>Horseshoe;</li>
	<li>Elastic net.</li>
  </ul>
	
<h3>Classificação</h3>
  <ul>
  <li>Regressão logística;</li>
  <li>Análise de discriminante linear;</li>
  <li>Análise de discriminante quadrática;</li>
  <li>Naive Bayes.</li>
  </ul>
	
<h3>Métodos baseados em árvores</h3>
  <ul>
  <li>Árvores de decisão;</li>
  <li>Randon Forest;</li>
  <li>Bootstrap Aggregation (Bagging);</li>
  <li>Boosting.</li>		
  </ul>
	
<h3>Support Vector Machines</h3>
  <ul>
  <li>Maximal Margin Classifier;</li>
  <li>Support vector Classifier;</li>
  <li>Kernels.</li>
  </ul>
	
<h3>Aprendizado não supervisionado</h3>
  <ul>
  <li>Análise de componentes principais;</li>
  <li>K-means Clustering;</li>
  <li>Hierarchical Clustering;</li>
  <li>DBSCAN.</li>		
  </ul>
	
<h3>Redes Neurais Artificiais</h3>
  <ul>
  <li>Introdução;</li>
  <li>Backpropagation algorithm;</li>
  <li>Aplicações.</li>
  </ul>	

<hr>
	
<h1 id="list_types">Referências Bibliográficas</h1>          
   
	<ul>
  <li>James, G., Witten, D., Hastie, T. e Tibshirani, [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Sixth%20Printing.pdf), 2013 (livro-texto), [Unofficial Solutions](http://blog.princehonest.com/stat-learning);</li>
  <li>Hastie, T., Tibshirani, R. e Friedman, J., [The Elements of Statistical Learning](http://statweb.stanford.edu/~tibs/ElemStatLearn/), 2009;</li>
  <li>Lantz, B., Machine Learning with R, Packt Publishing, 2013;</li>
	<li>Tan, Steinbach, and Kumar, [Introduction to Data Mining](http://www-users.cs.umn.edu/~kumar/dmbook/index.php), Addison-Wesley, 2005;</li>
  <li>Bishop, Pattern Recognition and Machine Learning, 2006;</li>
  <li>Ripley, Pattern Recognition and Neural Networks, 1996.</li>
  </ul>	

<hr>	

 <h1 id="list_types">Data Repositories</h1>          
   
	<ul>
  <li>[Kaggle](http://www.kaggle.com/)</li>
  <li>[UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/)</li>
  <li>[KDD Nugets](http://www.kdnuggets.com/datasets/)</li>
	<li>[TwitteR](http://cran.r-project.org/web/packages/twitteR/index.html)</li>
  <li>[rfigshare](http://cran.r-project.org/web/packages/rfigshare/index.html)</li>
  <li>Open Gov. Data: [dados.gov.br](http://dados.gov.br/), [www.data.gov](http://www.data.gov/), [www.data.gov.uk](http://www.data.gov.uk/);</li>
  </ul>

<hr>
	
</center>	
	
</div>
</div>
